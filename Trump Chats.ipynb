{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump's latest call with a world leader has given everyone a case of impeachment fever. The summarized transcript has been released ([link](https://www.cnn.com/interactive/2019/09/politics/trump-ukraine-transcript-annotated/)) and it's fairly easy to see why the fever is so contagious. However, this is a \"rough\" transcript based on what the notetaker recalled about the conversation. Now, people are also getting worked up about what may be missing from the transcript. One senator did a readout of the transcripts and suggested that there may be 20 minutes of conversation missing ([link](https://www.newsweek.com/senator-king-suggests-least-20-minutes-are-missing-trump-ukraine-call-transcript-1462622)). However, I think the only thing that's missing is allowance for translation which I will show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I set dictionaries with information on each transcript. Dictionaries are one of my favourite things to use in Python and I like to throw them in when I can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'nieto': {'link': 'https://raw.githubusercontent.com/sampurkiss/Misc/master/Trump/Data/call%20with%20nieto.txt', \n",
    "                   'date': 'January 27, 2017, FROM 9:35', 'length in mins': 53},\n",
    "\t\t 'turnbull':  {'link': 'https://raw.githubusercontent.com/sampurkiss/Misc/master/Trump/Data/call%20with%20turnbull.txt', \n",
    "                       'date': 'January 28, 2017 5:05 PM', 'length in mins': 24},\n",
    "\t\t 'zelenskyy': {'link': 'https://raw.githubusercontent.com/sampurkiss/Misc/master/Trump/Data/call%20with%20zelenskyy.txt', \n",
    "                       'date': 'July 25, 2019, 9:03 PM', 'length in mins': 30}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question I'm interested in is what do we know about these calls? We know what the administration has claimed was said, and we know how long the conversation lasted. There were [two leaked transcripts](https://www.washingtonpost.com/graphics/2017/politics/australia-mexico-transcripts/) provided to the Washington Post some months ago which can give us context for what a normal Trump conversation with a world leader might be like. These two can be used to get an idea of whether or not Trump's call with the Ukrainian president fits into the patterns of a \"normal\" conversation.\n",
    "\n",
    "I cleaned transcripts of the calls for further data analysis and pull them in below. I also created a column that counts the number of words used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript=pd.DataFrame()\n",
    "\n",
    "for leader in files.keys(): \n",
    "    link = files[leader]['link']\n",
    "    d=list()\n",
    "    f = urllib.request.urlopen(link) \n",
    "    for line in f:\n",
    "        d.append(line.decode('latin-1'))\n",
    "        file = leader\n",
    "    temp = pd.DataFrame({'transcript': file, 'lines': d[1:]})\n",
    "    new = temp['lines'].str.split(':', n=2, expand = True)\n",
    "    temp['speaker'] = new[0]\n",
    "    temp['lines'] = new[1]\n",
    "    transcript = pd.concat([transcript, temp])\n",
    "    \n",
    "    \n",
    "transcript['speaker']= transcript['speaker'].str.replace('The President', 'TRUMP')\n",
    "transcript['speaker']= transcript['speaker'].str.replace('President Zelenskyy', 'ZELENSKYY')\n",
    "transcript['num of words'] = transcript['lines'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at line 4 of the Nieto transcript, you'll notice that Nieto switches to Spanish. Nieto would presumably speak Spanish, a translator on Trump's side would translate to English, Trump would reply in English and a translator on Nieto's side would translate to Spanish. As a result of the translation, every conversation would take about twice as long and use twice as many words. If we're going to compare the conversations we have to account for the fact that all sentences must be repeated twice. This complicates things, but for simplicity I've assumed that all Trump and Nieto words are doubled as a result which should be approximately correct. It also seems reasonable to expect that Zelenskyy would have spoken his native language and used a translator as well (which has been confirmed by at least the Washington Post). \n",
    "\n",
    "To adjust for this, I simply double the number of words used by the world leaders in the Mexican and Ukrainian conversations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['num of words'] = np.where(transcript['transcript'] =='zelenskyy',\n",
    "                                      transcript['num of words']*2, \n",
    "                                      transcript['num of words'])\n",
    "\n",
    "transcript['num of words'] = np.where(transcript['transcript'] =='nieto',\n",
    "                                      transcript['num of words']*2, \n",
    "                                      transcript['num of words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to see what the differences are is to compare the numbe of words used per minute. This should give us a sense of how chatty Trump and friends are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >num of words</th>        <th class=\"col_heading level0 col1\" >words per min</th>    </tr>    <tr>        <th class=\"index_name level0\" >transcript</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21flevel0_row0\" class=\"row_heading level0 row0\" >nieto</th>\n",
       "                        <td id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21frow0_col0\" class=\"data row0 col0\" >6902</td>\n",
       "                        <td id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21frow0_col1\" class=\"data row0 col1\" >130</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21flevel0_row1\" class=\"row_heading level0 row1\" >turnbull</th>\n",
       "                        <td id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21frow1_col0\" class=\"data row1 col0\" >3198</td>\n",
       "                        <td id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21frow1_col1\" class=\"data row1 col1\" >133</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21flevel0_row2\" class=\"row_heading level0 row2\" >zelenskyy</th>\n",
       "                        <td id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21frow2_col0\" class=\"data row2 col0\" >3912</td>\n",
       "                        <td id=\"T_9e6643a8_e7e6_11e9_96cd_f8597161e21frow2_col1\" class=\"data row2 col1\" >130</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20c284c0cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = transcript.groupby(by ='transcript').sum()\n",
    "words[ 'words per min'] =None\n",
    "for name in words.index:\n",
    "\twords.loc[name, 'words per min'] = words.loc[name, 'num of words'] / files[name]['length in mins']\n",
    "words['words per min'] = (words['words per min']\n",
    "                                      .astype(float).round(0).astype(int))    \n",
    "words.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all the calls clock in at about 130 words used per minute. What's even more noticeable is that the Nieto and Zelenskyy transcript, both of which required a translator, clock in at identical words per minute. Even if you remove the translation adjustment, the result is identical.\n",
    "\n",
    "\n",
    "Another way to approach this is to look at number of words used by each leader in each conversation to see if there are any differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >transcript</th>        <th class=\"col_heading level0 col1\" >speaker</th>        <th class=\"col_heading level0 col2\" >num of words</th>        <th class=\"col_heading level0 col3\" >words per min</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21flevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow0_col0\" class=\"data row0 col0\" >nieto</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow0_col1\" class=\"data row0 col1\" >PENA NIETO</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow0_col2\" class=\"data row0 col2\" >3126</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow0_col3\" class=\"data row0 col3\" >59</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21flevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow1_col0\" class=\"data row1 col0\" >nieto</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow1_col1\" class=\"data row1 col1\" >TRUMP</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow1_col2\" class=\"data row1 col2\" >3776</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow1_col3\" class=\"data row1 col3\" >71</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21flevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow2_col0\" class=\"data row2 col0\" >turnbull</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow2_col1\" class=\"data row2 col1\" >TRUMP</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow2_col2\" class=\"data row2 col2\" >1686</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow2_col3\" class=\"data row2 col3\" >70</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21flevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow3_col0\" class=\"data row3 col0\" >turnbull</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow3_col1\" class=\"data row3 col1\" >TURNBULL</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow3_col2\" class=\"data row3 col2\" >1512</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow3_col3\" class=\"data row3 col3\" >63</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21flevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow4_col0\" class=\"data row4 col0\" >zelenskyy</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow4_col1\" class=\"data row4 col1\" >TRUMP</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow4_col2\" class=\"data row4 col2\" >1508</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow4_col3\" class=\"data row4 col3\" >50</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21flevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow5_col0\" class=\"data row5 col0\" >zelenskyy</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow5_col1\" class=\"data row5 col1\" >ZELENSKYY</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow5_col2\" class=\"data row5 col2\" >2404</td>\n",
       "                        <td id=\"T_b8c66db4_e7e6_11e9_9609_f8597161e21frow5_col3\" class=\"data row5 col3\" >80</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20c284c0fd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_per_speaker =transcript.groupby(by =['transcript', 'speaker']).sum().reset_index()\n",
    "words_per_speaker [ 'words per min'] =None\n",
    "for name in words_per_speaker['transcript']:\n",
    "\twords_per_speaker [ 'words per min']  = np.where(words_per_speaker['transcript'] ==name, words_per_speaker['num of words']/ files[name]['length in mins'],\n",
    "\t\t\t\t\t\t\t  words_per_speaker['words per min'])\n",
    "words_per_speaker['words per min'] = (words_per_speaker['words per min']\n",
    "                                      .astype(float).round(0).astype(int))\n",
    "words_per_speaker.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely, in the Nieto and Turnbull call, Trump manages to say about 70 words per minute and the other world leaders squeeze in about 60. However, in the Zelenskyy call, Trump only manages 50 words per minute and Zelenskyy speaks 80. This indicates that, for some reason, Trump spoke 30% less and Zelenskyy spoke 30% more. \n",
    "\n",
    "So, we already know that the the transcript isn't the full transcript. We know it's been edited down somehow. My main question is, did Trump really speak a lot less? Did Zelenskyy really speak a lot more? Or have things been modified to hide one or the other? \n",
    "\n",
    "Next step, I want to translate the English words into the respective language to get a more accurate sense of how many words were actually used. I think King et. al. want to accurately assess what's missing, they should use the transcript with translation. The other thing I hope to do is use sentiment analysis to dig into how each conversation actually went. Unfortunately transcripts between Trump and world leaders are notoriously hard to get (for good reason, probably) so, even though I'd love to run more ML analysis, the training set is probably a bit too small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
